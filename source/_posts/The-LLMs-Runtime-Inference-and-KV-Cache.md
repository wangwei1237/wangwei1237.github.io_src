---
title: 大模型的运行时推理和 KV Cache
reward: false
top: false
date: 2024-11-16 09:17:39
authors:
categories:
  - LLM
tags:
  - Prefill
  - KV Cache
  - Runtime Inference
---

![](Prefill-and-decoding-phase-in-the-LLM-inference.png)
<!--more-->